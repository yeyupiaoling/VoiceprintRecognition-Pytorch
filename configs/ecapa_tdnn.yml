# 数据集参数
dataset_conf:
  dataset:
    # 过滤最短的音频长度
    min_duration: 0.3
    # 最长的音频长度，大于这个长度会裁剪掉
    max_duration: 3
    # 音频的采样率
    sample_rate: 16000
    # 是否对音频进行音量归一化
    use_dB_normalization: True
    # 对音频进行音量归一化的音量分贝值
    target_dB: -20
  sampler:
    # 训练的批量大小
    batch_size: 128
    # 是否丢弃最后一个样本
    drop_last: True
  dataLoader:
    # 读取数据的线程数量
    num_workers: 8
  # 评估的数据要特殊处理
  eval_conf:
    # 评估的批量大小
    batch_size: 16
    # 最长的音频长度
    max_duration: 20
  # 训练数据的数据列表路径
  train_list: 'dataset/train_list.txt'
  # 评估注册的数据列表路径
  enroll_list: 'dataset/cn-celeb-test/enroll_list.txt'
  # 评估检验的数据列表路径
  trials_list: 'dataset/cn-celeb-test/trials_list.txt'
  # 是否使用PKSampler，该Sampler可以保证每个说话人都有sample_per_id个样本
  is_use_pksampler: False
  # 使用PKSampler时设置样本数量
  sample_per_id: 4

# 数据预处理参数
preprocess_conf:
  # 是否使用HF上的Wav2Vec2类似模型提取音频特征
  use_hf_model: False
  # 音频预处理方法，也可以叫特征提取方法
  # 当use_hf_model为False时，支持：MelSpectrogram、Spectrogram、MFCC、Fbank
  # 当use_hf_model为True时，指定的是HuggingFace的模型或者本地路径，比如facebook/w2v-bert-2.0或者./feature_models/w2v-bert-2.0
  feature_method: 'Fbank'
  # 当use_hf_model为False时，设置API参数，更参数查看对应API，不清楚的可以直接删除该部分，直接使用默认值。
  # 当use_hf_model为True时，可以设置参数use_gpu，指定是否使用GPU提取特征
  method_args:
    sample_frequency: 16000
    num_mel_bins: 80

model_conf:
  # 所使用的模型
  model: 'EcapaTdnn'
  # 模型参数
  model_args:
    embd_dim: 192
    # 所使用的池化层，支持ASP、SAP、TSP、TAP
    pooling_type: 'ASP'
    channels: [512, 512, 512, 512, 1536]
  # 分类器参数
  classifier:
    # 分类器类型，支持Cosine、Linear
    classifier_type: 'Cosine'
    # 说话人数量，即分类大小
    num_speakers: 2796
    num_blocks: 0

loss_conf:
  # 所使用的损失函数，支持AAMLoss、SphereFace2、AMLoss、ARMLoss、CELoss、SubCenterLoss、TripletAngularMarginLoss
  loss: 'AAMLoss'
  # 损失函数参数
  loss_args:
    margin: 0.2
    scale: 32
    easy_margin: False
    label_smoothing: 0.0
  # 是否使用损失函数margin调度器
  use_margin_scheduler: True
  # margin调度器参数
  margin_scheduler_args:
    initial_margin: 0.0
    final_margin: 0.3

optimizer_conf:
  # 优化方法
  optimizer: 'Adam'
  # 优化方法参数
  optimizer_args:
    lr: 0.001
    weight_decay: !!float 1e-5
  # 学习率衰减函数，支持Pytorch支持的和项目提供的WarmupCosineSchedulerLR
  scheduler: 'WarmupCosineSchedulerLR'
  # 学习率衰减函数参数
  scheduler_args:
    min_lr: !!float 1e-5
    max_lr: 0.001
    warmup_epoch: 5

train_conf:
  # 是否开启自动混合精度
  enable_amp: False
  # 是否使用Pytorch2.0的编译器
  use_compile: False
  # 训练的轮数
  max_epoch: 60
  log_interval: 100
